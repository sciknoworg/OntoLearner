SKH-NLP Team
===============

Description
-----------

.. sidebar:: Examples

    * SKH-NLP Learner Taxonomy Discovery (Supervised Fine-Tuning) Example: `llm_learner_skhnlp_sft_taxonomoy_discovery.py <https://github.com/sciknoworg/OntoLearner/blob/main/examples/llm_learner_skhnlp_sft_taxonomoy_discovery.py>`_
    * SKH-NLP Learner Taxonomy Discovery (Zero-Shot) Example: `llm_learner_skhnlp_zs_taxonomoy_discovery.py <https://github.com/sciknoworg/OntoLearner/blob/main/examples/llm_learner_skhnlp_zs_taxonomoy_discovery.py>`_

The Taxonomy Discovery task was modeled as a classification problem and addressed using two approaches. Intial experimentation was done on BERT, fine-tuned with various prompts in a classification setup. Experimentation was also done on LLaMA3 70B, experimenting with different prompt formulations for optimal results. Evaluation employed substring and Levenshtein distance functions to assess answer correctness.

Dataset:

The GeoNames dataset was used, containing 476 (child, parent) pairs with 9 distinct parent classes, making it a 9-class classification problem. To train the BERT classifier, a negative dataset was generated by (1) reversing records (swapping parent and child) and (2) manipulating records (randomly replacing the parent with one of the other 8).

Proposed Methods:

BERT-Based Approach: Modeled as a multi-class problem with 9 classes using a single binary classifier iteratively for each class. The model was fine-tuned to determine whether an is-a relationship exists between a given (parent, child) pair.

LLaMA-Based Approach: Evaluation focused on prompt engineering using two concepts—classification (instance–class) and hierarchy (is-a, parent–child). In some cases, the model partially used class names (e.g., only part of “mountain, hill, rock”). To handle this, substring matching and Levenshtein distance were applied during evaluation to map outputs to the closest class titles.


Loading Ontological Data
----------------------------------
We start by importing necessary components from the ontolearner package, loading ontology, and doing train-test splits.


.. code-block:: python

    from ontolearner import AutoRetrieverLearner, AgrO, train_test_split, evaluation_report

    ontology = AgrO()

    ontology.load()

    ontological_data = ontology.extract()

    train_data, test_data = train_test_split(ontological_data, test_size=0.2, random_state=42)


Initialize Learner
----------------------------------

Before defining the Retriever learner, choose the task you want the Retriever to perform. Available tasks has been described in `LLMs4OL Paradigms <https://ontolearner.readthedocs.io/learning_tasks/llms4ol.html>`_. The task IDs are: 'term-typing', 'taxonomy-discovery', 'non-taxonomic-re'.

.. code-block:: python

    task = 'term-typing'

Next, initiate the learner by specifying ``top_k`` parameter and load the desired ``sentence-transformer`` based model as a retriever.

.. code-block:: python

    ret_learner = AutoRetrieverLearner(top_k=5)

    ret_learner.load(model_id='sentence-transformers/all-MiniLM-L6-v2')

    # Index the model on the training data for LLMs4OL task
    ret_learner.fit(train_data, task=task)

    predicts = ret_learner.predict(test_data, task=task)

    truth = ret_learner.tasks_ground_truth_former(data=test_data, task=task)

    metrics = evaluation_report(y_true=truth, y_pred=predicts, task=task)

    print(metrics)

You will see a evaluations results.

.. hint::

    OntoLearner supports various retrieval models, including:

    * Various `sentence-transformers <https://huggingface.co/sentence-transformers>`_ models
    * T5 models (e.g., "google/flan-t5-base")
    * Nomic-AI models


Pipeline Usage
-----------------------

.. contents::
   :local:
   :depth: 2

-------------------------------
Supervised Fine-Tuning Pipeline 
-------------------------------

The pipeline example focuses on taxonomy-discovery using supervised fine-tuning, 
demonstrating how to adapt the pipeline for a different ontology or learner.

.. code-block:: python

    # Import core modules from the OntoLearner library
    from ontolearner import GeoNames, train_test_split, LearnerPipeline
    from ontolearner import SKHNLPSequentialFTLearner

    # Load ontology and split
    # Load the GeoNames ontology for taxonomy discovery.
    # GeoNames provides geographic parent-child relationships (is-a hierarchy).
    ontology = GeoNames()
    ontology.load()
    data = ontology.extract()

    # Split the taxonomic relationships into train and test sets
    train_data, test_data = train_test_split(
        data,
        test_size=0.2,
        random_state=42
    )

    # Configure the learner with user-defined training args + device
    # Configure the supervised BERT SFT Learner for taxonomy discovery.
    # This fine-tunes BERT-Large using Sequential Prompts on (Parent, Child) pairs.
    bert_learner = SKHNLPSequentialFTLearner(
        model_name="bert-large-uncased",
        n_prompts=2,
        random_state=1403,
        device="cpu", # Note: CPU training for BERT-Large is very slow.
        output_dir="./results/",
        num_train_epochs=1,
        per_device_train_batch_size=8,
        per_device_eval_batch_size=8,
        warmup_steps=500,
        weight_decay=0.01,
        logging_dir="./logs/",
        logging_steps=50,
        eval_strategy="epoch",
        save_strategy="epoch",
        load_best_model_at_end=True,
    )

    # Build pipeline and run
    # Build the pipeline, passing the BERT Learner.
    pipeline = LearnerPipeline(
        llm=bert_learner,
        llm_id="bert-large-uncased",
        ontologizer_data=False,
    )

    # Run the full learning pipeline on the taxonomy-discovery task
    outputs = pipeline(
        train_data=train_data,
        test_data=test_data,
        task="taxonomy-discovery",
        evaluate=True,
        ontologizer_data=False,
    )

    # Display the evaluation results
    print("Metrics:", outputs.get("metrics"))

    # Display total elapsed time for training + prediction + evaluation
    print("Elapsed time:", outputs["elapsed_time"])

    # Print all returned outputs (include predictions)
    print(outputs)


-------------------------------
Zero-Shot Pipeline 
-------------------------------

The pipeline example focuses on taxonomy-discovery using zero-shot learning, 
demonstrating how to adapt the pipeline for a different ontology or learner.

.. code-block:: python

    # Import core modules from the OntoLearner library
    from ontolearner import GeoNames, train_test_split, LearnerPipeline, SKHNLPZSLearner

    #Load ontology and split data
    # The GeoNames ontology provides geographic term types and relationships.
    ontology = GeoNames()
    ontology.load()
    train_data, test_data = train_test_split(
        ontology.extract(),
        test_size=0.2,
        random_state=42,
    )

    # Configure the learner with user-defined generation and normalization settings
    # Configure the Zero-Shot Qwen Learner for taxonomy discovery.
    # This model uses a fixed prompt and string normalization (Levenshtein) to classify terms.
    llm_learner = SKHNLPZSLearner(
        model_name="Qwen/Qwen2.5-0.5B-Instruct",
        device="cpu",               # use "cuda" if you have a GPU
        max_new_tokens=16,
        save_path="./outputs/",     # directory or full file path for CSV
        verbose=True,
        normalize_mode="levenshtein",      # "none" | "substring" | "levenshtein" | "auto"
    )

    # Build pipeline and run
    pipe = LearnerPipeline(
        llm=llm_learner,
        llm_id="Qwen/Qwen2.5-0.5B-Instruct",
        ontologizer_data=False,
        device="cpu",
    )

    # Run the full learning pipeline on the taxonomy-discovery task
    outputs = pipe(
        train_data=train_data,        # zero-shot; ignored by the LLM learner
        test_data=test_data,
        task="taxonomy-discovery",
        evaluate=True,
        ontologizer_data=False,
    )

    # Display the evaluation results
    print("Metrics:", outputs.get("metrics"))

    # Display total elapsed time for training + prediction + evaluation
    print("Elapsed time:", outputs["elapsed_time"])

    # Print all returned outputs (include predictions)
    print(outputs)